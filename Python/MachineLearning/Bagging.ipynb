{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7678eb9-4448-4e3a-93e7-43bc08ecc186",
   "metadata": {},
   "source": [
    "# bootstrap aggregating(Bagging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6ff4420-fbae-4abf-a9a1-403bffffe298",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1728\n",
      "Distribution of safety ratings in 1728 of data:\n",
      "safety\n",
      "low     0.333333\n",
      "med     0.333333\n",
      "high    0.333333\n",
      "Name: proportion, dtype: float64\n",
      "Distribution of safety ratings in bootstrapped sample data:\n",
      "safety\n",
      "high    0.340856\n",
      "med     0.332176\n",
      "low     0.326968\n",
      "Name: proportion, dtype: float64\n",
      "0.33296064814814813\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average low percentage: 0.333\n",
      "95% Confidence Interval for low percengage: (0.3108,0.3553)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#Models from scikit learn module:\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/car/car.data', names=['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety', 'accep'])\n",
    "df['accep'] = ~(df['accep']=='unacc') #1 is acceptable, 0 if not acceptable\n",
    "X = pd.get_dummies(df.iloc[:,0:6], drop_first=True)\n",
    "y = df['accep']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X,y, random_state=0, test_size=0.25)\n",
    "nrows = df.shape[0]\n",
    "\n",
    "## 1. Print number of rows and distribution of safety ratings\n",
    "print(nrows)\n",
    "print(f'Distribution of safety ratings in {nrows} of data:')\n",
    "print(df.safety.value_counts(normalize=True))\n",
    "\n",
    "## 2. Create bootstrapped sample\n",
    "boot_sample = df.sample(nrows, replace=True)\n",
    "print(f'Distribution of safety ratings in bootstrapped sample data:')\n",
    "print(boot_sample.safety.value_counts(normalize=True))\n",
    "\n",
    "\n",
    "## 3. Create 1000 bootstrapped samples\n",
    "low_perc = []\n",
    "for i in range(1000):\n",
    "    boot_sample = df.sample(nrows, replace=True)\n",
    "    low_perc.append(boot_sample.safety.value_counts(normalize=True)['low'])\n",
    "\n",
    "## 4. Plot a histogram of the low percentage values\n",
    "mean_lp = np.mean(low_perc) \n",
    "print(mean_lp)\n",
    "plt.hist(low_perc, bins=20);\n",
    "plt.xlabel('Low Percentage')\n",
    "plt.show()\n",
    "\n",
    "## 5. What are the 2.5 and 97.5 percentiles?\n",
    "print(f'Average low percentage: {np.mean(low_perc).round(4)}')\n",
    "\n",
    "low_perc.sort()\n",
    "print(f'95% Confidence Interval for low percengage: ({low_perc[25].round(4)},{low_perc[975].round(4)})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3238551a-8e5d-4126-bac6-7f3f69ee56fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of DT on test set (trained using full set): 0.8588\n",
      "Accuracy score of DT on test set (trained using bootstrapped sample): 0.8912\n",
      "Accuracy score of aggregated 10 bootstrapped samples:0.9097\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/car/car.data', names=['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety', 'accep'])\n",
    "df['accep'] = ~(df['accep']=='unacc') #1 is acceptable, 0 if not acceptable\n",
    "X = pd.get_dummies(df.iloc[:,0:6], drop_first=True)\n",
    "y = df['accep']\n",
    "x_train, x_test, y_train, y_test = train_test_split(X,y, random_state=0, test_size=0.25)\n",
    "\n",
    "#original decision tree trained on full training set\n",
    "dt = DecisionTreeClassifier(max_depth=5)\n",
    "dt.fit(x_train, y_train)\n",
    "print(f'Accuracy score of DT on test set (trained using full set): {dt.score(x_test, y_test).round(4)}')\n",
    "\n",
    "#2. New decision tree trained on bootstrapped sample\n",
    "dt2 = DecisionTreeClassifier(max_depth=5)\n",
    "#ids are the indices of the bootstrapped sample\n",
    "ids = x_train.sample(x_train.shape[0], replace=True, random_state=0).index\n",
    "dt2.fit(x_train.loc[ids], y_train[ids])#max_depth=50,criterion='gini')\n",
    "print(f'Accuracy score of DT on test set (trained using bootstrapped sample): {dt2.score(x_test, y_test).round(4)}')\n",
    "\n",
    "## 3. Bootstapping ten samples and aggregating the results:\n",
    "preds = []\n",
    "random_state = 0\n",
    "for i in range(10):\n",
    "    ids = x_train.sample(x_train.shape[0], replace=True, random_state=random_state+i).index\n",
    "    dt2.fit(x_train.loc[ids], y_train[ids])\n",
    "    preds.append(dt2.predict(x_test))   \n",
    "ba_pred = np.array(preds).mean(0)\n",
    "\n",
    "# 4. Calculate accuracy of the bagged sample\n",
    "ba_accuracy = accuracy_score(ba_pred>=0.5, y_test)\n",
    "print(f'Accuracy score of aggregated 10 bootstrapped samples:{ba_accuracy.round(4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cef7851e-ccfa-4c11-8303-43677d025444",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of DT on test set (trained using full feature set):\n",
      "0.9513888888888888\n",
      "Accuracy score of DT on test set (trained using random feature sample):\n",
      "0.6851851851851852\n",
      "Accuracy score of aggregated 10 samples:\n",
      "0.7453703703703703\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/car/car.data', names=['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety', 'accep'])\n",
    "df['accep'] = ~(df['accep']=='unacc') #1 is acceptable, 0 if not acceptable\n",
    "X = pd.get_dummies(df.iloc[:,0:6], drop_first=True)\n",
    "y = df['accep']\n",
    "x_train, x_test, y_train, y_test = train_test_split(X,y, random_state=0, test_size=0.25)\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(x_train, y_train)\n",
    "print(\"Accuracy score of DT on test set (trained using full feature set):\")\n",
    "accuracy_dt = dt.score(x_test, y_test)\n",
    "print(accuracy_dt)\n",
    "\n",
    "# 1. Create rand_features, random samples from the set of features\n",
    "rand_features = np.random.choice(x_train.columns,10)\n",
    "\n",
    "# Make new decision tree trained on random sample of 10 features and calculate the new accuracy score\n",
    "dt2 = DecisionTreeClassifier()\n",
    "\n",
    "dt2.fit(x_train[rand_features], y_train)\n",
    "print(\"Accuracy score of DT on test set (trained using random feature sample):\")\n",
    "accuracy_dt2 = dt2.score(x_test[rand_features], y_test)\n",
    "print(accuracy_dt2)\n",
    "\n",
    "# 2. Build decision trees on 10 different random samples \n",
    "predictions = []\n",
    "for i in range(10):\n",
    "    rand_features = np.random.choice(x_train.columns,10)\n",
    "    dt2.fit(x_train[rand_features], y_train)\n",
    "    predictions.append(dt2.predict(x_test[rand_features]))\n",
    "\n",
    "## 3. Get aggregate predictions and accuracy score\n",
    "prob_predictions = np.array(predictions).mean(0)\n",
    "agg_predictions = (prob_predictions>0.5)\n",
    "agg_accuracy = accuracy_score(agg_predictions, y_test)\n",
    "print('Accuracy score of aggregated 10 samples:')\n",
    "print(agg_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be8283b-4c74-48a9-a01f-38fff628ac22",
   "metadata": {},
   "source": [
    "# Bagging in `scikit-learn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6fe48208-dc39-4e7e-9361-c99d2a940bc6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of Bagged Classifier, 10 estimators:\n",
      "0.9050925925925926\n",
      "Accuracy score of Bagged Classifier, 10 estimators, 10 max features:\n",
      "0.8958333333333334\n",
      "Accuracy score of Logistic Regression, 10 estimators:\n",
      "0.9143518518518519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benson/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "/Users/benson/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "/Users/benson/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/car/car.data', names=['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety', 'accep'])\n",
    "df['accep'] = ~(df['accep']=='unacc') #1 is acceptable, 0 if not acceptable\n",
    "X = pd.get_dummies(df.iloc[:,0:6], drop_first=True)\n",
    "y = df['accep']\n",
    "x_train, x_test, y_train, y_test = train_test_split(X,y, random_state=0, test_size=0.25)\n",
    "\n",
    "# 1. Bagging classifier with 10 Decision Tree base estimators\n",
    "bag_dt = BaggingClassifier(base_estimator=DecisionTreeClassifier(max_depth=5), n_estimators=10)\n",
    "bag_dt.fit(x_train, y_train)\n",
    "\n",
    "print('Accuracy score of Bagged Classifier, 10 estimators:')\n",
    "bag_accuracy = bag_dt.score(x_test, y_test)\n",
    "print(bag_accuracy)\n",
    "\n",
    "# 2.Set `max_features` to 10.\n",
    "bag_dt_10 = BaggingClassifier(base_estimator=DecisionTreeClassifier(max_depth=5), n_estimators=10, max_features=10)\n",
    "bag_dt_10.fit(x_train, y_train)\n",
    "\n",
    "print('Accuracy score of Bagged Classifier, 10 estimators, 10 max features:')\n",
    "bag_accuracy_10 = bag_dt_10.score(x_test, y_test)\n",
    "print(bag_accuracy_10)\n",
    "\n",
    "\n",
    "# 3. Change base estimator to Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "bag_lr = BaggingClassifier(base_estimator=LogisticRegression(), n_estimators=10, max_features=10)\n",
    "bag_lr.fit(x_train, y_train)\n",
    "\n",
    "print('Accuracy score of Logistic Regression, 10 estimators:')\n",
    "bag_accuracy_lr = bag_lr.score(x_test, y_test)\n",
    "print(bag_accuracy_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85dbcf06-8544-4f74-90d0-2b00e0f42c4e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest parameters:\n",
      "{'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': None, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Test set accuracy:\n",
      "0.9652777777777778\n",
      "Test set precision: 0.9548872180451128\n",
      "Test set recall: 0.9338235294117647\n",
      "Test set confusion matrix:\n",
      "[[290   6]\n",
      " [  9 127]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/car/car.data', names=['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety', 'accep'])\n",
    "df['accep'] = ~(df['accep']=='unacc') #1 is acceptable, 0 if not acceptable\n",
    "X = pd.get_dummies(df.iloc[:,0:6], drop_first=True)\n",
    "y = df['accep']\n",
    "x_train, x_test, y_train, y_test = train_test_split(X,y, random_state=0, test_size=0.25)\n",
    "\n",
    "# 1. Create a Random Forest Classifier and print its parameters\n",
    "rf = RandomForestClassifier()\n",
    "print('Random Forest parameters:')\n",
    "rf_params = rf.get_params()\n",
    "print(rf_params)\n",
    "\n",
    "# 2. Fit the Random Forest Classifier to training data and calculate accuracy score on the test data\n",
    "rf.fit(x_train, y_train)\n",
    "y_pred = rf.predict(x_test)\n",
    "print('Test set accuracy:')\n",
    "rf_accuracy = rf.score(x_test, y_test)\n",
    "print(rf_accuracy)\n",
    "\n",
    "# 3. Calculate Precision and Recall scores and the Confusion Matrix\n",
    "rf_precision = precision_score(y_test, y_pred)\n",
    "print(f'Test set precision: {rf_precision}')\n",
    "rf_recall = recall_score(y_test, y_pred)\n",
    "print(f'Test set recall: {rf_recall}')\n",
    "rf_confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(f'Test set confusion matrix:\\n{rf_confusion_matrix}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "590e8298-35a9-4abb-8fc0-9aec80987d76",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count     1728.000000\n",
      "mean     36804.271508\n",
      "std      13319.762383\n",
      "min       4033.591733\n",
      "25%      26052.630612\n",
      "50%      36908.896105\n",
      "75%      47284.811408\n",
      "max      70185.428305\n",
      "Name: price, dtype: float64\n",
      "Train set R^2: 0.9764507971693032\n",
      "Test set R^2: 0.8458691724312803\n",
      "Avg Price Train/Test: 36804.27150837884\n",
      "Train set MAE: 1628.3092834821286\n",
      "Test set MAE: 4264.455313505622\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "\n",
    "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/car/car.data', names=['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety', 'accep'])\n",
    "df['accep'] = ~(df['accep']=='unacc') #1 is acceptable, 0 if not acceptable\n",
    "X = pd.get_dummies(df.iloc[:,0:6], drop_first=True)\n",
    "\n",
    "## Generating some fake prices for regression! :) \n",
    "fake_prices = (15000 + 25*df.index.values)+np.random.normal(size=df.shape[0])*5000\n",
    "df['price'] = fake_prices\n",
    "print(df.price.describe())\n",
    "y = df['price']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X,y, random_state=0, test_size=0.25)\n",
    "\n",
    "# 1. Create a Random Regressor and print `R^2` scores on training and test data\n",
    "rfr = RandomForestRegressor()\n",
    "rfr.fit(x_train, y_train)\n",
    "\n",
    "r_squared_train = rfr.score(x_train, y_train)\n",
    "print(f'Train set R^2: {r_squared_train}')\n",
    "\n",
    "r_squared_test = rfr.score(x_test, y_test)\n",
    "print(f'Test set R^2: {r_squared_test}')\n",
    "\n",
    "# 2. Print Mean Absolute Error on training and test data\n",
    "\n",
    "avg_price = y.mean()\n",
    "print(f'Avg Price Train/Test: {avg_price}')\n",
    "\n",
    "y_pred_train =rfr.predict(x_train)\n",
    "y_pred_test =rfr.predict(x_test)\n",
    "\n",
    "mae_train = mean_absolute_error(y_train, y_pred_train)\n",
    "print(f'Train set MAE: {mae_train}')\n",
    "\n",
    "mae_test = mean_absolute_error(y_test, y_pred_test)\n",
    "print(f'Test set MAE: {mae_test}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "695689a8-753f-4788-808e-1dc9979e95bd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.00\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 加載資料\n",
    "data = load_iris()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "# 分割資料\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# 建立 Random Forest 模型\n",
    "rf = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42)\n",
    "\n",
    "# 訓練模型\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# 預測\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# 評估\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
